# .gitlab-ci.yml â€” ZenMarket Forecaster CI/CD (perf/chopguard-v0.2.1)
# Gate: fail when weekday_gaps > 0 (toggle via ENFORCE_GAPS=strict|off)

variables:
  PIP_DISABLE_PIP_VERSION_CHECK: "1"
  PIP_CACHE_DIR: "$CI_PROJECT_DIR/.cache/pip"
  PYTHONPATH: "$CI_PROJECT_DIR/vscode_snowflake_starter/src"
  ENFORCE_GAPS: "strict"   # set to "off" to allow gaps without failing

default:
  image: python:3.11
  cache:
    key: "$CI_JOB_IMAGE"
    paths:
      - .cache/pip
  before_script:
    - python --version
    - pip install --upgrade pip
    - pip install --upgrade -r vscode_snowflake_starter/requirements.txt snowflake-connector-python
    - echo "PYTHONPATH=$PYTHONPATH"

stages: [exec, reports]

audit_cli:
  stage: exec
  script:
    - echo "=== EXEC STAGE START ==="
    - python -c "import snowflake; print('snowflake import OK')"
    - python vscode_snowflake_starter/src/exec_audit_summary.py
    - AUDIT_DIR="$(ls -dt vscode_snowflake_starter/audit_exports/stage1_exec_* | head -1)"
    - echo "AUDIT_DIR=$AUDIT_DIR" > exec.env
    - echo "EXEC_READY=true" >> exec.env
    # ---- gate: fail if weekday_gaps > 0 when ENFORCE_GAPS=strict ----
    - |
      GAPS=$(awk -F, '$1=="weekday_gaps"{print $2}' "$AUDIT_DIR/summary.csv")
      echo "weekday_gaps=$GAPS (enforce=$ENFORCE_GAPS)"
      if [ "${ENFORCE_GAPS}" = "strict" ] && [ "${GAPS:-0}" -gt 0 ]; then
        echo "âŒ Weekday gaps detected ($GAPS). Failing per policy."; exit 1
      else
        echo "âœ… Gate passed."
      fi
    - echo "=== EXEC STAGE DONE ==="
  artifacts:
    when: always
    paths:
      - "$AUDIT_DIR/REPORT_EXEC.md"
      - "$AUDIT_DIR/summary.csv"
    reports:
      dotenv: exec.env
    expire_in: 1 week
  rules:
    - if: '$CI_COMMIT_BRANCH == "perf/chopguard-v0.2.1"'
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'

publish_exec_report:
  stage: reports
  needs: ["audit_cli"]
  script:
    - echo "EXEC_READY=${EXEC_READY}"
    - test "${EXEC_READY}" = "true"
    - echo "AUDIT_DIR=${AUDIT_DIR}"
    - test -d "${AUDIT_DIR}"
    - echo "===== REPORT_EXEC.md (head) ====="
    - head -50 "${AUDIT_DIR}/REPORT_EXEC.md"
    - echo "===== summary.csv (tail) ====="
    - tail -20 "${AUDIT_DIR}/summary.csv"
  dependencies: ["audit_cli"]
  artifacts:
    when: always
    paths:
      - "${AUDIT_DIR:-vscode_snowflake_starter/audit_exports}/"
    expire_in: 1 week
  rules:
    - if: '$CI_COMMIT_BRANCH == "perf/chopguard-v0.2.1"'
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'

# -----------------------------
# Slack notifications (webhooks)
# -----------------------------
# Requirements:
#   - CI/CD variables:
#       SLACK_WEBHOOK_MR            -> webhook for #zen-forecaster-mr
#       SLACK_WEBHOOK_INCIDENTS     -> webhook for #zen-forecaster-incidents
#   - No Claude, no bot token; plain webhooks via Python stdlib

slack_mr_update:
  stage: reports
  needs: ["audit_cli"]
  rules:
    # Post to MR channel for any MR-triggered pipeline (pass/fail)
    - if: '$CI_PIPELINE_SOURCE == "merge_request_event"'
  script:
    - |
      python - <<'PY'
      import json, os, urllib.request
      hook = os.environ.get("SLACK_WEBHOOK_MR")
      if not hook:
          raise SystemExit("SLACK_WEBHOOK_MR not set")
      title = os.environ.get("CI_MERGE_REQUEST_TITLE","(no title)")
      iid   = os.environ.get("CI_MERGE_REQUEST_IID","?")
      proj  = os.environ.get("CI_PROJECT_PATH","")
      mrurl = os.environ.get("CI_MERGE_REQUEST_PROJECT_URL","") + f"/-/merge_requests/{iid}"
      purl  = os.environ.get("CI_PIPELINE_URL","")
      pid   = os.environ.get("CI_PIPELINE_ID","")
      status= os.environ.get("CI_PIPELINE_STATUS","")
      text  = f"*MR:* <{mrurl}|!{iid}> â€¢ *{title}*\n*Pipeline:* <{purl}|#{pid}> â€¢ *Status:* {status}"
      payload = {"text":"MR Update","blocks":[{"type":"section","text":{"type":"mrkdwn","text":text}}]}
      req = urllib.request.Request(hook, data=json.dumps(payload).encode(), headers={"Content-Type":"application/json"})
      with urllib.request.urlopen(req) as r: r.read()
      print("Posted MR update")
      PY

slack_incident_on_fail:
  stage: reports
  needs: ["audit_cli","publish_exec_report"]
  when: always
  rules:
    # Fire only on failed pipelines
    - if: '$CI_PIPELINE_STATUS == "failed"'
      when: always
  script:
    - |
      python - <<'PY'
      import os, json, urllib.request, pathlib, csv
      hook = os.environ.get("SLACK_WEBHOOK_INCIDENTS")
      if not hook:
          raise SystemExit("SLACK_WEBHOOK_INCIDENTS not set")
      proj  = os.environ.get("CI_PROJECT_PATH","")
      branch= os.environ.get("CI_COMMIT_BRANCH","")
      purl  = os.environ.get("CI_PIPELINE_URL","")
      pid   = os.environ.get("CI_PIPELINE_ID","")
      sha   = os.environ.get("CI_COMMIT_SHA","")
      short = os.environ.get("CI_COMMIT_SHORT_SHA", sha[:8])
      # Try to include weekday_gaps from latest summary.csv
      gaps="n/a"
      audit_dir = os.environ.get("AUDIT_DIR","")
      if audit_dir:
          try:
              with open(str(pathlib.Path(audit_dir)/"summary.csv"), newline="") as f:
                  for row in csv.DictReader(f):
                      if row.get("check")=="weekday_gaps":
                          gaps = row.get("violations","n/a")
                          break
          except Exception:
              pass
      text = (
          f"ðŸš¨ *Pipeline FAILED*\n"
          f"*Project:* {proj}\n*Branch:* {branch}\n"
          f"<{purl}|Pipeline #{pid}> â€¢ <{os.environ.get('CI_PROJECT_URL')}/-/commit/{sha}|{short}>\n"
          f"*weekday_gaps:* {gaps}"
      )
      payload = {"text":"PIPELINE FAILED","blocks":[
          {"type":"header","text":{"type":"plain_text","text":"ðŸš¨ Pipeline Failed"}},
          {"type":"section","text":{"type":"mrkdwn","text":text}}
      ]}
      req = urllib.request.Request(hook, data=json.dumps(payload).encode(), headers={"Content-Type":"application/json"})
      with urllib.request.urlopen(req) as r: r.read()
      print("Posted incident alert")
      PY
