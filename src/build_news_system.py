#!/usr/bin/env python3
"""
Automated News Infrastructure Builder
Builds production news ingestion system based on RSS feed testing results
"""

import os
import feedparser
import requests
from datetime import datetime, timedelta
import json
from typing import Dict, List

class NewsSystemBuilder:
    def __init__(self):
        # High-quality feeds identified from testing
        self.production_feeds = {
            "fed_news": {
                "url": "https://www.federalreserve.gov/feeds/press_all.xml",
                "relevance": 90.0,
                "category": "macro_policy",
                "priority": 1
            },
            "cnbc_economy": {
                "url": "https://www.cnbc.com/id/20910258/device/rss/rss.html", 
                "relevance": 60.0,
                "category": "economic_data",
                "priority": 2
            },
            "seeking_alpha": {
                "url": "https://seekingalpha.com/market_currents.xml",
                "relevance": 57.1,
                "category": "market_analysis", 
                "priority": 3
            },
            "marketwatch_breaking": {
                "url": "http://feeds.marketwatch.com/marketwatch/realtimeheadlines/",
                "relevance": 50.0,
                "category": "breaking_news",
                "priority": 4
            }
        }
        
    def create_news_ingestion_module(self):
        """Generate the production news ingestion Python module"""
        
        news_ingestion_code = '''#!/usr/bin/env python3
"""
Production News Ingestion System
Automatically ingests news from verified RSS feeds for forecasting integration
Generated by automated news system builder
"""

import feedparser
import requests
from datetime import datetime, timedelta
import sys
import os
import hashlib
from typing import Dict, List, Optional

# Add src to path for imports
sys.path.append(os.path.join(os.path.dirname(__file__)))

try:
    from snowflake_conn import get_snowflake_connection
    SNOWFLAKE_AVAILABLE = True
except ImportError:
    print("Warning: Snowflake connection not available")
    SNOWFLAKE_AVAILABLE = False

class ProductionNewsIngester:
    def __init__(self):
        self.feeds = ''' + str(self.production_feeds) + '''
        
    def fetch_feed_articles(self, feed_name: str, feed_config: dict) -> List[Dict]:
        """Fetch and parse articles from RSS feed"""
        try:
            response = requests.get(feed_config["url"], timeout=10, headers={
                'User-Agent': 'ZenMarket-Forecaster/1.0'
            })
            
            if response.status_code != 200:
                print(f"Failed to fetch {feed_name}: HTTP {response.status_code}")
                return []
                
            feed = feedparser.parse(response.content)
            
            if feed.bozo:
                print(f"Warning: {feed_name} returned malformed RSS")
                
            articles = []
            for entry in feed.entries[:20]:  # Latest 20 articles
                
                # Generate unique ID for article
                article_id = hashlib.md5(
                    f"{feed_name}_{entry.get('title', '')}_{entry.get('link', '')}".encode()
                ).hexdigest()[:16]
                
                # Parse publish date
                pub_date = None
                if 'published_parsed' in entry:
                    try:
                        pub_date = datetime(*entry.published_parsed[:6])
                    except:
                        pass
                        
                # Only include recent articles (last 7 days)
                if pub_date and pub_date < datetime.now() - timedelta(days=7):
                    continue
                    
                article = {
                    "article_id": article_id,
                    "source": feed_name,
                    "category": feed_config["category"],
                    "priority": feed_config["priority"],
                    "title": entry.get('title', ''),
                    "summary": entry.get('summary', ''),
                    "link": entry.get('link', ''),
                    "published_date": pub_date,
                    "ingested_date": datetime.now(),
                    "relevance_score": feed_config["relevance"]
                }
                
                articles.append(article)
                
            print(f"✅ {feed_name}: {len(articles)} articles ingested")
            return articles
            
        except Exception as e:
            print(f"❌ {feed_name}: {str(e)}")
            return []
    
    def store_articles(self, articles: List[Dict]) -> bool:
        """Store articles in database (Snowflake if available, otherwise JSON)"""
        
        if not articles:
            return True
            
        if SNOWFLAKE_AVAILABLE:
            try:
                return self._store_to_snowflake(articles)
            except Exception as e:
                print(f"Snowflake storage failed: {e}")
                return self._store_to_json(articles)
        else:
            return self._store_to_json(articles)
    
    def _store_to_snowflake(self, articles: List[Dict]) -> bool:
        """Store articles to Snowflake database"""
        conn = get_snowflake_connection()
        cursor = conn.cursor()
        
        # Create table if not exists
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS NEWS_ARTICLES (
            ARTICLE_ID VARCHAR(16) PRIMARY KEY,
            SOURCE VARCHAR(50),
            CATEGORY VARCHAR(50), 
            PRIORITY INTEGER,
            TITLE VARCHAR(1000),
            SUMMARY VARCHAR(5000),
            LINK VARCHAR(1000),
            PUBLISHED_DATE TIMESTAMP_NTZ,
            INGESTED_DATE TIMESTAMP_NTZ,
            RELEVANCE_SCORE DECIMAL(5,2)
        )
        """)
        
        # Insert articles with MERGE to avoid duplicates
        for article in articles:
            cursor.execute("""
            MERGE INTO NEWS_ARTICLES n
            USING (SELECT %(article_id)s as ARTICLE_ID) s
            ON n.ARTICLE_ID = s.ARTICLE_ID
            WHEN NOT MATCHED THEN INSERT (
                ARTICLE_ID, SOURCE, CATEGORY, PRIORITY, TITLE, SUMMARY, 
                LINK, PUBLISHED_DATE, INGESTED_DATE, RELEVANCE_SCORE
            ) VALUES (
                %(article_id)s, %(source)s, %(category)s, %(priority)s, %(title)s, 
                %(summary)s, %(link)s, %(published_date)s, %(ingested_date)s, %(relevance_score)s
            )
            """, article)
        
        conn.commit()
        cursor.close()
        conn.close()
        
        print(f"✅ Stored {len(articles)} articles to Snowflake NEWS_ARTICLES table")
        return True
        
    def _store_to_json(self, articles: List[Dict]) -> bool:
        """Fallback: Store articles to JSON file"""
        
        # Create output directory
        os.makedirs("output/news", exist_ok=True)
        
        # Convert datetime objects to strings for JSON serialization
        json_articles = []
        for article in articles:
            json_article = article.copy()
            for key, value in json_article.items():
                if isinstance(value, datetime):
                    json_article[key] = value.isoformat()
            json_articles.append(json_article)
        
        # Save to timestamped file
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"output/news/news_articles_{timestamp}.json"
        
        with open(filename, 'w') as f:
            json.dump(json_articles, f, indent=2)
            
        print(f"✅ Stored {len(articles)} articles to {filename}")
        return True
    
    def run_full_ingestion(self) -> bool:
        """Run complete news ingestion process"""
        print("=== PRODUCTION NEWS INGESTION ===")
        print(f"Fetching from {len(self.feeds)} verified sources...")
        
        all_articles = []
        
        # Fetch from all feeds
        for feed_name, feed_config in self.feeds.items():
            articles = self.fetch_feed_articles(feed_name, feed_config)
            all_articles.extend(articles)
            
        print(f"Total articles collected: {len(all_articles)}")
        
        # Store articles
        if all_articles:
            success = self.store_articles(all_articles)
            if success:
                print("✅ News ingestion completed successfully")
                return True
            else:
                print("❌ News storage failed")
                return False
        else:
            print("⚠️  No articles collected")
            return True

def main():
    """Main entry point"""
    ingester = ProductionNewsIngester()
    success = ingester.run_full_ingestion()
    return 0 if success else 1

if __name__ == "__main__":
    exit(main())
'''
        
        # Save the generated code
        with open("src/news_ingestion.py", "w") as f:
            f.write(news_ingestion_code)
            
        print("✅ Generated production news ingestion system: src/news_ingestion.py")
        
    def create_integration_test(self):
        """Create test module for news integration"""
        
        test_code = '''#!/usr/bin/env python3
"""
News Integration Test
Tests the news ingestion system integration
"""

import sys
import os
sys.path.append('src')

def test_news_integration():
    """Test news system integration"""
    print("=== TESTING NEWS INTEGRATION ===")
    
    try:
        from news_ingestion import ProductionNewsIngester
        print("✅ News ingestion module imported successfully")
        
        ingester = ProductionNewsIngester() 
        print(f"✅ Ingester initialized with {len(ingester.feeds)} feeds")
        
        # Test one feed
        test_feed = list(ingester.feeds.items())[0]
        feed_name, feed_config = test_feed
        print(f"Testing feed: {feed_name}")
        
        articles = ingester.fetch_feed_articles(feed_name, feed_config)
        if articles:
            print(f"✅ Successfully fetched {len(articles)} articles from {feed_name}")
            print("✅ News integration test PASSED")
            return True
        else:
            print(f"⚠️  No articles fetched from {feed_name}, but no errors")
            print("✅ News integration test PASSED (no articles available)")
            return True
            
    except Exception as e:
        print(f"❌ News integration test FAILED: {str(e)}")
        return False

def main():
    success = test_news_integration()
    return 0 if success else 1

if __name__ == "__main__":
    exit(main())
'''
        
        with open("src/test_news_integration.py", "w") as f:
            f.write(test_code)
            
        print("✅ Generated news integration test: src/test_news_integration.py")

def main():
    """Build complete news infrastructure"""
    print("=== AUTOMATED NEWS SYSTEM BUILDER ===")
    print("Building production news infrastructure...")
    
    builder = NewsSystemBuilder()
    
    # Generate news ingestion system
    builder.create_news_ingestion_module()
    
    # Generate integration test
    builder.create_integration_test()
    
    print("=== NEWS INFRASTRUCTURE BUILD COMPLETE ===")
    print("Generated files:")
    print("- src/news_ingestion.py (production ingestion system)")
    print("- src/test_news_integration.py (integration test)")
    
    return 0

if __name__ == "__main__":
    exit(main())